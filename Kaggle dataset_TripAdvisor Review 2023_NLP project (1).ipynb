{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:43.372623Z",
     "iopub.status.busy": "2023-05-23T13:36:43.372122Z",
     "iopub.status.idle": "2023-05-23T13:36:43.396202Z",
     "shell.execute_reply": "2023-05-23T13:36:43.394974Z",
     "shell.execute_reply.started": "2023-05-23T13:36:43.372586Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose first Sentiment Analysic in which will be analyzing the review to determine if the emotional tone of the message is positive, negative, or neutral. However, before that I would like to apply a normal structure for a NLP processing steps wise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Read the Text Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:43.399584Z",
     "iopub.status.busy": "2023-05-23T13:36:43.398566Z",
     "iopub.status.idle": "2023-05-23T13:36:44.727222Z",
     "shell.execute_reply": "2023-05-23T13:36:44.726033Z",
     "shell.execute_reply.started": "2023-05-23T13:36:43.399472Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:44.729207Z",
     "iopub.status.busy": "2023-05-23T13:36:44.728376Z",
     "iopub.status.idle": "2023-05-23T13:36:46.403202Z",
     "shell.execute_reply": "2023-05-23T13:36:46.401815Z",
     "shell.execute_reply.started": "2023-05-23T13:36:44.729175Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chardet\n",
    "\n",
    "dataset_path = r\"D:\\Huyen\\Data Science\\Kaggle Projects\\New_Delhi_reviews.csv\"\n",
    "\n",
    "# Read the file in binary mode and detect the encoding\n",
    "with open(dataset_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "\n",
    "# Get the detected encoding\n",
    "encoding = result['encoding']\n",
    "\n",
    "# Read the file using the detected encoding\n",
    "df = pd.read_csv(dataset_path, encoding=encoding)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:46.406116Z",
     "iopub.status.busy": "2023-05-23T13:36:46.405744Z",
     "iopub.status.idle": "2023-05-23T13:36:46.438396Z",
     "shell.execute_reply": "2023-05-23T13:36:46.437073Z",
     "shell.execute_reply.started": "2023-05-23T13:36:46.406084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_review</th>\n",
       "      <th>review_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Totally in love with the Auro of the place, re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I went this bar 8 days regularly with my husba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We were few friends and was a birthday celebra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fatjar Cafe and Market is the perfect place fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hey Guys, if you are craving for pizza and sea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating_review                                        review_full\n",
       "0              5  Totally in love with the Auro of the place, re...\n",
       "1              5  I went this bar 8 days regularly with my husba...\n",
       "2              5  We were few friends and was a birthday celebra...\n",
       "3              5  Fatjar Cafe and Market is the perfect place fo...\n",
       "4              5  Hey Guys, if you are craving for pizza and sea..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:46.441224Z",
     "iopub.status.busy": "2023-05-23T13:36:46.440023Z",
     "iopub.status.idle": "2023-05-23T13:36:46.448742Z",
     "shell.execute_reply": "2023-05-23T13:36:46.447674Z",
     "shell.execute_reply.started": "2023-05-23T13:36:46.441179Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:46.451104Z",
     "iopub.status.busy": "2023-05-23T13:36:46.450416Z",
     "iopub.status.idle": "2023-05-23T13:36:46.474024Z",
     "shell.execute_reply": "2023-05-23T13:36:46.471483Z",
     "shell.execute_reply.started": "2023-05-23T13:36:46.451070Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    697\n",
       "4    244\n",
       "3     36\n",
       "2     12\n",
       "1     10\n",
       "Name: rating_review, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what portion of our review are distributed in the dataset\n",
    "\n",
    "df['rating_review'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:46.479268Z",
     "iopub.status.busy": "2023-05-23T13:36:46.475584Z",
     "iopub.status.idle": "2023-05-23T13:36:46.512274Z",
     "shell.execute_reply": "2023-05-23T13:36:46.511181Z",
     "shell.execute_reply.started": "2023-05-23T13:36:46.479221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nulls in rating_review:0\n",
      "Number of nulls in review:0\n"
     ]
    }
   ],
   "source": [
    "#Check for missing value\n",
    "\n",
    "print('Number of nulls in rating_review:{}'.format(df['rating_review'].isnull().sum()))\n",
    "print('Number of nulls in review:{}'.format(df['review_full'].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above dataset has 2 null value in the review, consider that we have a good number of review, we can choose to remove this null value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:46.514098Z",
     "iopub.status.busy": "2023-05-23T13:36:46.513700Z",
     "iopub.status.idle": "2023-05-23T13:36:46.605659Z",
     "shell.execute_reply": "2023-05-23T13:36:46.604642Z",
     "shell.execute_reply.started": "2023-05-23T13:36:46.514064Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna(subset =['review_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:46.608192Z",
     "iopub.status.busy": "2023-05-23T13:36:46.607107Z",
     "iopub.status.idle": "2023-05-23T13:36:46.614655Z",
     "shell.execute_reply": "2023-05-23T13:36:46.613570Z",
     "shell.execute_reply.started": "2023-05-23T13:36:46.608154Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(999, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-Processing Text Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:46.620024Z",
     "iopub.status.busy": "2023-05-23T13:36:46.619586Z",
     "iopub.status.idle": "2023-05-23T13:36:46.629712Z",
     "shell.execute_reply": "2023-05-23T13:36:46.628520Z",
     "shell.execute_reply.started": "2023-05-23T13:36:46.619988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Punctuation\n",
    "\n",
    "import string\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:46.631884Z",
     "iopub.status.busy": "2023-05-23T13:36:46.631514Z",
     "iopub.status.idle": "2023-05-23T13:36:57.059107Z",
     "shell.execute_reply": "2023-05-23T13:36:57.057713Z",
     "shell.execute_reply.started": "2023-05-23T13:36:46.631853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_review</th>\n",
       "      <th>review_full</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Totally in love with the Auro of the place, re...</td>\n",
       "      <td>Totally in love with the Auro of the place rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I went this bar 8 days regularly with my husba...</td>\n",
       "      <td>I went this bar 8 days regularly with my husba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We were few friends and was a birthday celebra...</td>\n",
       "      <td>We were few friends and was a birthday celebra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fatjar Cafe and Market is the perfect place fo...</td>\n",
       "      <td>Fatjar Cafe and Market is the perfect place fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hey Guys, if you are craving for pizza and sea...</td>\n",
       "      <td>Hey Guys if you are craving for pizza and sear...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating_review                                        review_full  \\\n",
       "0              5  Totally in love with the Auro of the place, re...   \n",
       "1              5  I went this bar 8 days regularly with my husba...   \n",
       "2              5  We were few friends and was a birthday celebra...   \n",
       "3              5  Fatjar Cafe and Market is the perfect place fo...   \n",
       "4              5  Hey Guys, if you are craving for pizza and sea...   \n",
       "\n",
       "                                              review  \n",
       "0  Totally in love with the Auro of the place rea...  \n",
       "1  I went this bar 8 days regularly with my husba...  \n",
       "2  We were few friends and was a birthday celebra...  \n",
       "3  Fatjar Cafe and Market is the perfect place fo...  \n",
       "4  Hey Guys if you are craving for pizza and sear...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(review_full):\n",
    "    review_full =\"\".join([char for char in review_full if char not in string.punctuation])\n",
    "    return review_full\n",
    "df['review'] = df['review_full'].apply(lambda x: remove_punct(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:36:57.061082Z",
     "iopub.status.busy": "2023-05-23T13:36:57.060626Z",
     "iopub.status.idle": "2023-05-23T13:37:04.164404Z",
     "shell.execute_reply": "2023-05-23T13:37:04.162881Z",
     "shell.execute_reply.started": "2023-05-23T13:36:57.061048Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_review</th>\n",
       "      <th>review_full</th>\n",
       "      <th>review</th>\n",
       "      <th>review_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Totally in love with the Auro of the place, re...</td>\n",
       "      <td>Totally in love with the Auro of the place rea...</td>\n",
       "      <td>[totally, in, love, with, the, auro, of, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I went this bar 8 days regularly with my husba...</td>\n",
       "      <td>I went this bar 8 days regularly with my husba...</td>\n",
       "      <td>[i, went, this, bar, 8, days, regularly, with,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We were few friends and was a birthday celebra...</td>\n",
       "      <td>We were few friends and was a birthday celebra...</td>\n",
       "      <td>[we, were, few, friends, and, was, a, birthday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fatjar Cafe and Market is the perfect place fo...</td>\n",
       "      <td>Fatjar Cafe and Market is the perfect place fo...</td>\n",
       "      <td>[fatjar, cafe, and, market, is, the, perfect, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hey Guys, if you are craving for pizza and sea...</td>\n",
       "      <td>Hey Guys if you are craving for pizza and sear...</td>\n",
       "      <td>[hey, guys, if, you, are, craving, for, pizza,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating_review                                        review_full  \\\n",
       "0              5  Totally in love with the Auro of the place, re...   \n",
       "1              5  I went this bar 8 days regularly with my husba...   \n",
       "2              5  We were few friends and was a birthday celebra...   \n",
       "3              5  Fatjar Cafe and Market is the perfect place fo...   \n",
       "4              5  Hey Guys, if you are craving for pizza and sea...   \n",
       "\n",
       "                                              review  \\\n",
       "0  Totally in love with the Auro of the place rea...   \n",
       "1  I went this bar 8 days regularly with my husba...   \n",
       "2  We were few friends and was a birthday celebra...   \n",
       "3  Fatjar Cafe and Market is the perfect place fo...   \n",
       "4  Hey Guys if you are craving for pizza and sear...   \n",
       "\n",
       "                                    review_tokenized  \n",
       "0  [totally, in, love, with, the, auro, of, the, ...  \n",
       "1  [i, went, this, bar, 8, days, regularly, with,...  \n",
       "2  [we, were, few, friends, and, was, a, birthday...  \n",
       "3  [fatjar, cafe, and, market, is, the, perfect, ...  \n",
       "4  [hey, guys, if, you, are, craving, for, pizza,...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenize\n",
    "\n",
    "#Define a function to split our sentences into a list of words\n",
    "\n",
    "import re\n",
    "\n",
    "def tokenize (review_full):\n",
    "    tokens = re.split('\\W+', review_full)\n",
    "    return tokens\n",
    "df['review_tokenized'] = df['review'].apply(lambda x: tokenize(x.lower()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:37:04.166198Z",
     "iopub.status.busy": "2023-05-23T13:37:04.165729Z",
     "iopub.status.idle": "2023-05-23T13:37:04.180582Z",
     "shell.execute_reply": "2023-05-23T13:37:04.179400Z",
     "shell.execute_reply.started": "2023-05-23T13:37:04.166152Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove Stopwords\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:37:04.183136Z",
     "iopub.status.busy": "2023-05-23T13:37:04.181851Z",
     "iopub.status.idle": "2023-05-23T13:37:25.839258Z",
     "shell.execute_reply": "2023-05-23T13:37:25.837989Z",
     "shell.execute_reply.started": "2023-05-23T13:37:04.183027Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating_review</th>\n",
       "      <th>review_full</th>\n",
       "      <th>review</th>\n",
       "      <th>review_tokenized</th>\n",
       "      <th>review_nonstop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Totally in love with the Auro of the place, re...</td>\n",
       "      <td>Totally in love with the Auro of the place rea...</td>\n",
       "      <td>[totally, in, love, with, the, auro, of, the, ...</td>\n",
       "      <td>[totally, love, auro, place, really, beautiful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>I went this bar 8 days regularly with my husba...</td>\n",
       "      <td>I went this bar 8 days regularly with my husba...</td>\n",
       "      <td>[i, went, this, bar, 8, days, regularly, with,...</td>\n",
       "      <td>[went, bar, 8, days, regularly, husband, fully...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>We were few friends and was a birthday celebra...</td>\n",
       "      <td>We were few friends and was a birthday celebra...</td>\n",
       "      <td>[we, were, few, friends, and, was, a, birthday...</td>\n",
       "      <td>[friends, birthday, celebration, food, good, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Fatjar Cafe and Market is the perfect place fo...</td>\n",
       "      <td>Fatjar Cafe and Market is the perfect place fo...</td>\n",
       "      <td>[fatjar, cafe, and, market, is, the, perfect, ...</td>\n",
       "      <td>[fatjar, cafe, market, perfect, place, casual,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Hey Guys, if you are craving for pizza and sea...</td>\n",
       "      <td>Hey Guys if you are craving for pizza and sear...</td>\n",
       "      <td>[hey, guys, if, you, are, craving, for, pizza,...</td>\n",
       "      <td>[hey, guys, craving, pizza, searching, visit, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating_review                                        review_full  \\\n",
       "0              5  Totally in love with the Auro of the place, re...   \n",
       "1              5  I went this bar 8 days regularly with my husba...   \n",
       "2              5  We were few friends and was a birthday celebra...   \n",
       "3              5  Fatjar Cafe and Market is the perfect place fo...   \n",
       "4              5  Hey Guys, if you are craving for pizza and sea...   \n",
       "\n",
       "                                              review  \\\n",
       "0  Totally in love with the Auro of the place rea...   \n",
       "1  I went this bar 8 days regularly with my husba...   \n",
       "2  We were few friends and was a birthday celebra...   \n",
       "3  Fatjar Cafe and Market is the perfect place fo...   \n",
       "4  Hey Guys if you are craving for pizza and sear...   \n",
       "\n",
       "                                    review_tokenized  \\\n",
       "0  [totally, in, love, with, the, auro, of, the, ...   \n",
       "1  [i, went, this, bar, 8, days, regularly, with,...   \n",
       "2  [we, were, few, friends, and, was, a, birthday...   \n",
       "3  [fatjar, cafe, and, market, is, the, perfect, ...   \n",
       "4  [hey, guys, if, you, are, craving, for, pizza,...   \n",
       "\n",
       "                                      review_nonstop  \n",
       "0  [totally, love, auro, place, really, beautiful...  \n",
       "1  [went, bar, 8, days, regularly, husband, fully...  \n",
       "2  [friends, birthday, celebration, food, good, t...  \n",
       "3  [fatjar, cafe, market, perfect, place, casual,...  \n",
       "4  [hey, guys, craving, pizza, searching, visit, ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Define a function to remove all stopwords\n",
    "\n",
    "def remove_stopwords(tokenized_review_full):\n",
    "    review_full = [word for word in tokenized_review_full if word not in stopwords]\n",
    "    return review_full\n",
    "\n",
    "df['review_nonstop'] = df['review_tokenized'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Save for later use) Define a function to handle all data cleaning\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \" \".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [wor for word in tokens if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:37:25.841392Z",
     "iopub.status.busy": "2023-05-23T13:37:25.840992Z",
     "iopub.status.idle": "2023-05-23T13:37:25.847925Z",
     "shell.execute_reply": "2023-05-23T13:37:25.846683Z",
     "shell.execute_reply.started": "2023-05-23T13:37:25.841359Z"
    }
   },
   "outputs": [],
   "source": [
    "#create function to clean text\n",
    "\n",
    "def clean_text(review_full):\n",
    "    review_full = \"\".join([word.lower() for word in review_full if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', review_full)\n",
    "    review_full = [word for word in tokens if word not in stopwords]\n",
    "    return review_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 6510)\n",
      "['' '01133036298' '1' ... 'zone' 'zucchini' 'éclair']\n"
     ]
    }
   ],
   "source": [
    "#Fit a basic TFIDF Vertorize and view the results\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(df['review_full'])\n",
    "\n",
    "print(X_tfidf.shape)\n",
    "\n",
    "feature_names = tfidf_vect.get_feature_names_out()\n",
    "print(feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 6644)\n",
      "['' '01133036298' '1' ... 'zone' 'zucchini' 'éclair']\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def clean_text(review_full):\n",
    "    review_full = \"\".join([word.lower() for word in review_full if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', review_full)\n",
    "    stopwords = ['review_nonstop']  # Define your list of stopwords here\n",
    "    review_full = [word for word in tokens if word not in stopwords]\n",
    "    return review_full\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(df['review_full'])\n",
    "\n",
    "print(X_tfidf.shape)\n",
    "\n",
    "feature_names = tfidf_vect.get_feature_names_out()\n",
    "print(feature_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:50:37.735694Z",
     "iopub.status.busy": "2023-05-23T13:50:37.735215Z",
     "iopub.status.idle": "2023-05-23T13:50:37.743709Z",
     "shell.execute_reply": "2023-05-23T13:50:37.742403Z",
     "shell.execute_reply.started": "2023-05-23T13:50:37.735656Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<999x6644 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 52665 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:54:14.598991Z",
     "iopub.status.busy": "2023-05-23T13:54:14.597942Z",
     "iopub.status.idle": "2023-05-23T13:54:56.996720Z",
     "shell.execute_reply": "2023-05-23T13:54:56.995483Z",
     "shell.execute_reply.started": "2023-05-23T13:54:14.598935Z"
    }
   },
   "outputs": [],
   "source": [
    "X_features = pd.DataFrame (X_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:56:17.004869Z",
     "iopub.status.busy": "2023-05-23T13:56:17.004404Z",
     "iopub.status.idle": "2023-05-23T13:56:17.054378Z",
     "shell.execute_reply": "2023-05-23T13:56:17.052954Z",
     "shell.execute_reply.started": "2023-05-23T13:56:17.004830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6634</th>\n",
       "      <th>6635</th>\n",
       "      <th>6636</th>\n",
       "      <th>6637</th>\n",
       "      <th>6638</th>\n",
       "      <th>6639</th>\n",
       "      <th>6640</th>\n",
       "      <th>6641</th>\n",
       "      <th>6642</th>\n",
       "      <th>6643</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.121570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6644 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0     1     2     3     4     5     6     7     8     9     ...  6634  \\\n",
       "0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "1  0.121570   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "2  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "3  0.075442   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "4  0.060349   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
       "\n",
       "   6635  6636  6637  6638  6639  6640  6641  6642  6643  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 6644 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore RandomForestClassifier Attributes & Hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T14:12:57.366131Z",
     "iopub.status.busy": "2023-05-23T14:12:57.364884Z",
     "iopub.status.idle": "2023-05-23T14:12:57.373790Z",
     "shell.execute_reply": "2023-05-23T14:12:57.372548Z",
     "shell.execute_reply.started": "2023-05-23T14:12:57.366081Z"
    }
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T14:13:48.630038Z",
     "iopub.status.busy": "2023-05-23T14:13:48.629555Z",
     "iopub.status.idle": "2023-05-23T14:13:48.637176Z",
     "shell.execute_reply": "2023-05-23T14:13:48.635790Z",
     "shell.execute_reply.started": "2023-05-23T14:13:48.630000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=10, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#import Random Foresh for Classification from sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "print(rf_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T14:14:39.371962Z",
     "iopub.status.busy": "2023-05-23T14:14:39.371547Z",
     "iopub.status.idle": "2023-05-23T14:14:39.377759Z",
     "shell.execute_reply": "2023-05-23T14:14:39.376465Z",
     "shell.execute_reply.started": "2023-05-23T14:14:39.371925Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T14:17:07.516131Z",
     "iopub.status.busy": "2023-05-23T14:17:07.515379Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, df['rating_review'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a basic Random Forest Model\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_model = rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions on the test set using the fit model\n",
    "y_pred = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.259/ Recall: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to '5') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to '5') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model prediction using precision & recall\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label='5', average='macro')\n",
    "recall = recall_score(y_test, y_pred, pos_label='5', average='macro')\n",
    "\n",
    "print('Precision: {}/ Recall: {}'.format(round(precision, 3), round(recall, 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Summary of the above code: \n",
    "\n",
    "Precision measures the ability of a classifier to correctly identify positive samples among the samples it predicted as positive. A precision score of 0.259 indicates that out of the samples predicted as positive, approximately 25.9% were actually positive.\n",
    "\n",
    "Recall, also known as sensitivity or true positive rate, measures the ability of a classifier to correctly identify positive samples among all the actual positive samples. A recall score of 0.208 suggests that approximately 20.8% of the actual positive samples were correctly identified by the classifier.\n",
    "\n",
    "Both precision and recall scores range from 0 to 1, with higher values indicating better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following we will do the same for Rating 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.259/ Recall: 0.208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1396: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'macro'). You may use labels=[pos_label] to specify a single positive class.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model prediction using precision & recall\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, pos_label='4', average='macro')\n",
    "recall = recall_score(y_test, y_pred, pos_label='4', average='macro')\n",
    "\n",
    "print('Precision: {}/ Recall: {}'.format(round(precision, 3), round(recall, 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Predict review rating from dataset of Review on the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.685\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df['review_full']  # Reviews as input features\n",
    "y = df['rating_review']  # Review ratings as target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Preprocess the text using TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectors = vectorizer.fit_transform(X_train)\n",
    "X_test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 4: Train a machine learning model\n",
    "model = LinearSVC()\n",
    "model.fit(X_train_vectors, y_train)\n",
    "\n",
    "# Step 5: Make predictions on the test set\n",
    "y_pred = model.predict(X_test_vectors)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.6619163763066201\n",
      "Recall: 0.685\n",
      "F1 Score: 0.636491043203372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision: Precision measures the proportion of correctly predicted positive instances (true positives) out of all instances predicted as positive. In your case, a precision of 0.6619163763066201 means that around 66.2% of the reviews predicted as positive were actually positive.\n",
    "\n",
    "Recall: Recall (also known as sensitivity) measures the proportion of correctly predicted positive instances (true positives) out of all actual positive instances. With a recall of 0.685, it means that approximately 68.5% of the actual positive reviews were correctly identified.\n",
    "\n",
    "F1 Score: The F1 score combines precision and recall into a single metric, providing a balance between the two. It is the harmonic mean of precision and recall. In your case, an F1 score of 0.636491043203372 indicates the overall performance of the model, considering both precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In short, we should not use this model for further prediction on the review need further tuning. As part of lesson we will not proceed this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
